# Data Quality Dashboard

Dieses Projekt ist ein umfassendes Tool zur Analyse und √úberwachung der Datenqualit√§t von Auftrags- und Positionsdaten. Es besteht aus einer ETL-Pipeline (Extract, Transform, Load), die Daten bereinigt und Metriken vorberechnet, sowie einem interaktiven Streamlit-Dashboard zur Visualisierung.

Das System nutzt **DuckDB** als performante Backend-Datenbank und **Evidently AI** f√ºr Data Drift Analysen. Zus√§tzlich kommen Machine Learning Komponenten (**Sentence Transformers**) zum Einsatz, um semantische Auff√§lligkeiten in Textdaten zu erkennen.

## Inhaltsverzeichnis

- [Features](#features)
- [Projektstruktur](#projektstruktur)
- [Voraussetzungen & Installation](#voraussetzungen--installation)
- [Datenvorbereitung](#datenvorbereitung)
- [Nutzung](#nutzung)
    - [1. Datenbank erstellen (ETL)](#1-datenbank-erstellen-etl)
    - [2. Dashboard starten](#2-dashboard-starten)
- [Dashboard-Bereiche](#dashboard-bereiche)

## Features

*   **Datenbereinigung:** Automatische Typkonvertierung, Behandlung von Null-Werten und Korrektur von Tippfehlern.
*   **Performance:** Vorberechnung komplexer Metriken und Speicherung in einer lokalen DuckDB-Datenbank f√ºr schnelles Laden im Dashboard.
*   **Plausibilit√§tspr√ºfungen:**
    *   Logik-Checks (z.B. *Forderung < Einigung*).
    *   Erkennung von Proforma-Belegen.
    *   Vorzeichen-Konsistenzpr√ºfungen.
    *   Abgleich von Auftragssummen mit der Summe der Positionen.
*   **Semantische Analyse:** KI-gest√ºtzte Pr√ºfung (mittels `SentenceTransformer`), ob das angegebene Gewerk zum Namen des Handwerkers passt.
*   **Data Drift:** Erkennung von Ver√§nderungen in der Datenverteilung √ºber die Zeit (Data Drift) mittels Evidently AI.
*   **Trendanalyse:** Vergleich aktueller Metriken mit dem vorherigen Datenbank-Stand (automatisches Backup/Rotation der DB).

## Projektstruktur

```text
.
‚îú‚îÄ‚îÄ resources/                  # Daten-Ordner
‚îÇ   ‚îú‚îÄ‚îÄ Auftragsdaten           # Raw Parquet Datei
‚îÇ   ‚îú‚îÄ‚îÄ Positionsdaten          # Raw Parquet Datei
‚îÇ   ‚îú‚îÄ‚îÄ Auftragsdaten_Zeit      # Raw Parquet Datei
‚îÇ   ‚îú‚îÄ‚îÄ dashboard_data.duckdb   # Generierte Datenbank (durch build_db.py)
‚îÇ   ‚îî‚îÄ‚îÄ reports/                # Generierte HTML Data Drift Reports
‚îú‚îÄ‚îÄ app_pages/                  # Streamlit Seiten-Logik
‚îÇ   ‚îú‚îÄ‚îÄ page1.py                # Startseite (KPIs & Trends)
‚îÇ   ‚îú‚îÄ‚îÄ page2.py                # Numerische Daten
‚îÇ   ‚îú‚îÄ‚îÄ page3.py                # Textuelle Daten
‚îÇ   ‚îú‚îÄ‚îÄ page4.py                # Plausibilit√§tscheck
‚îÇ   ‚îî‚îÄ‚îÄ page5.py                # Data Drift Reports
‚îú‚îÄ‚îÄ assets/                     # Bilder (Logos, Favicon)
‚îú‚îÄ‚îÄ build_db.py                 # ETL-Skript (MAIN: F√ºhrt Cleaning & Metriken aus)
‚îú‚îÄ‚îÄ data_cleaning.py            # Logik f√ºr Datenimport & Bereinigung
‚îú‚îÄ‚îÄ metrics.py                  # Bibliothek f√ºr alle Berechnungsfunktionen
‚îú‚îÄ‚îÄ data_drift_metrics.py       # Logik f√ºr Evidently AI Reports
‚îú‚îÄ‚îÄ db_dashboard.py             # Hauptanwendung (Streamlit App)
‚îî‚îÄ‚îÄ requirements.txt            # Python Abh√§ngigkeiten
```

## Voraussetzungen & Installation

Es wird Python 3.12+ empfohlen.

1.  **Repository klonen / Dateien ablegen.**
2.  **Abh√§ngigkeiten installieren:**

    Erstelle eine `requirements.txt` mit folgendem Inhalt (basierend auf den Imports):
    ```text
    pandas
    numpy
    duckdb
    streamlit
    streamlit-option-menu
    altair
    evidently
    sentence-transformers
    torch
    pyarrow
    fastparquet
    ```

    Installiere die Pakete:
    ```bash
    pip install -r requirements.txt
    ```

    *Hinweis: F√ºr die semantische Analyse wird `torch` ben√∂tigt. Falls eine GPU verf√ºgbar ist (CUDA), wird diese automatisch genutzt, um die Berechnung zu beschleunigen.*

## Datenvorbereitung

Das Skript erwartet drei `.parquet` Dateien im Ordner `resources/`:

1.  **`Auftragsdaten`**: Enth√§lt die Kopfdaten der Auftr√§ge (IDs, Betr√§ge, Kundengruppe, etc.).
2.  **`Positionsdaten`**: Enth√§lt die Detailpositionen zu den Auftr√§gen.
3.  **`Auftragsdaten_Zeit`**: Enth√§lt Zeitstempel-Informationen (`KvaRechnung_ID`, `CRMEingangszeit`), die an die Auftr√§ge gemerged werden.

Stelle sicher, dass diese Dateien vorhanden sind, bevor das ETL-Skript ausgef√ºhrt wird.

## Nutzung

### 1. Datenbank erstellen (ETL)

Bevor das Dashboard gestartet werden kann, m√ºssen die Daten bereinigt und die Metriken berechnet werden. Dies √ºbernimmt das Skript `build_db.py`.

```bash
python build_db.py
```

**Was passiert hier?**
*   L√§dt die Raw-Daten.
*   F√ºhrt `data_cleaning.py` aus.
*   Berechnet alle Metriken aus `metrics.py` (inkl. aufwendiger KI-Berechnungen).
*   Erstellt/Ersetzt `resources/dashboard_data.duckdb`.
*   Rotiert die alte Datenbank zu `dashboard_data_old.duckdb`, um Trendvergleiche zu erm√∂glichen.

### 2. Dashboard starten

Nach erfolgreicher Erstellung der Datenbank kann das Dashboard gestartet werden. Nutze hierf√ºr `db_dashboard.py`, da dieses f√ºr die Nutzung der Datenbank optimiert ist.

```bash
streamlit run db_dashboard.py
```

*(Hinweis: `Dashboard.py` ist eine Legacy-Variante, die Berechnungen On-The-Fly durchf√ºhrt und weniger performant ist).*

## üìä Dashboard-Bereiche

Das Dashboard ist in 5 Bereiche unterteilt:

1.  **Startseite:**
    *   Globale KPIs (Anzahl Zeilen, Null-Quoten, Unique-Checks).
    *   √úbersicht der Fehlerh√§ufigkeit (Heatmap nach Wochentag/Stunde).
    *   Trendverlauf der Positionen pro Auftrag.

2.  **Numerische Daten:**
    *   Analyse von numerischen Ausrei√üern.
    *   Checks auf Auftr√§ge > 50.000‚Ç¨.
    *   **Summenabgleich:** Pr√ºft, ob `Auftragssumme == Summe(Positionen)`.
    *   Zeitwert-Fehler.

3.  **Textuelle Daten:**
    *   Erkennung von Testdaten ("Test" in Kundengruppe).
    *   **Handwerker vs. Gewerk Analyse:**
        *   *Regelbasiert:* Ungew√∂hnliche Gewerk-H√§ufigkeiten pro Handwerker.
        *   *Semantisch:* KI-Vergleich, ob der Handwerkername zum Gewerk passt (z.B. "Maler M√ºller" macht "Elektroinstallation" -> Fehler).

4.  **Plausibilit√§tscheck:**
    *   Detaillierte Analyse von Logikfehlern.
    *   **Forderung vs. Einigung:** F√§lle, in denen mehr geeinigt als gefordert wurde.
    *   **Rabatt-Check:** Validierung von negativen Betr√§gen basierend auf Bezeichnungen (Skonto, Storno, etc.).
    *   **Vorzeichen-Logik:** Inkonsistenzen zwischen Menge, Einzelpreis und Gesamtpreis.
    *   Proforma-Belege (Einigung zwischen 0,01‚Ç¨ und 1,00‚Ç¨).
    *   Auftr√§ge ohne Positionen (Anzahl der Auftr√§ge, denen keine Positionen zugeordnet sind (PositionsAnzahl ist leer))
    *   Ausrei√üer in der Forderungssumme (1. & 99. Perzentil je Schadensart)

5.  **Data Drift:**
    *   Erstellung und Anzeige von HTML-Reports mittels Evidently AI.
    *   Vergleich von zwei Zeitr√§umen (Referenz vs. Vergleichszeitraum), um festzustellen, ob sich die Datencharakteristik signifikant ver√§ndert hat.

---

### Fehlerbehebung

*   **FileNotFoundError:** Stelle sicher, dass der Ordner `resources/` existiert und die Parquet-Dateien dort liegen.
*   **Performance:** Der erste Lauf von `build_db.py` kann aufgrund der `SentenceTransformer` Berechnungen (Download des Modells und Inferenz) einige Zeit dauern.
*   **Datenbank gesperrt:** Wenn das Dashboard l√§uft, ist die DuckDB im Read-Only Modus. F√ºr einen neuen `build_db.py` Lauf sollte das Dashboard idealerweise gestoppt oder sichergestellt werden, dass keine Schreibkonflikte auftreten (obwohl das Skript versucht, dies zu handhaben).