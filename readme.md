***

# Data Quality Dashboard

Ein interaktives Dashboard zur Analyse, Ãœberwachung und Validierung von DatenqualitÃ¤t in Auftrags- und Positionsdaten. Das Projekt nutzt **Streamlit** fÃ¼r das Frontend, **DuckDB** als performante In-Memory-Datenbank und **Evidently** zur Analyse von Data Drift. ZusÃ¤tzlich kommen NLP-Modelle (**Sentence Transformers**) zum Einsatz, um semantische AuffÃ¤lligkeiten in Textfeldern zu erkennen.

## ðŸ“‹ Features

Das Dashboard ist in fÃ¼nf Hauptbereiche unterteilt:

1.  **Startseite (Overview):**
    *   Zentrale KPIs (Zeilenanzahl, Null-Werte-Quoten, Eindeutigkeit der IDs).
    *   Visualisierung von Fehlerschwerpunkten nach Wochentag und Uhrzeit (Heatmap).
    *   Trendanalyse der Positionen pro Auftrag.
2.  **Numerische Daten:**
    *   Validierung von Zeitwert-Berechnungen.
    *   Erkennung von AusreiÃŸern (z.B. AuftrÃ¤ge > 50.000 â‚¬).
    *   Abgleich von Auftragssummen gegen die Summe der Positionen.
3.  **Textuelle Daten:**
    *   Erkennung von TestdatensÃ¤tzen.
    *   **NLP-Analyse:** Semantischer Abgleich zwischen "Handwerker" und "Gewerk" (nutzt `paraphrase-multilingual-MiniLM-L12-v2`), um falsche Zuordnungen zu finden.
4.  **PlausibilitÃ¤tscheck:**
    *   Logik-PrÃ¼fungen: Ist die Einigung hÃ¶her als die Forderung?
    *   Rabatt-Validierung: Sind Rabatte korrekt als Abzug gekennzeichnet?
    *   Erkennung von Proforma-Belegen.
    *   Vorzeichen-Logik (Tripel-Check: Forderung, Empfehlung, Einigung).
5.  **Data Drift:**
    *   Integration von **Evidently AI** zur Erkennung von VerteilungsÃ¤nderungen in den Daten Ã¼ber verschiedene ZeitrÃ¤ume.

## ðŸ›  Technologie-Stack

*   **Frontend:** [Streamlit](https://streamlit.io/)
*   **Datenbank:** [DuckDB](https://duckdb.org/)
*   **Data Science & Manipulation:** Pandas, NumPy
*   **Visualisierung:** Altair
*   **Machine Learning / NLP:** PyTorch, SentenceTransformers
*   **Monitoring:** Evidently

## ðŸ“‚ Projektstruktur

```text
.
â”œâ”€â”€ app_pages/                  # EnthÃ¤lt die Logik fÃ¼r die einzelnen Dashboard-Seiten
â”‚   â”œâ”€â”€ page1.py                # Startseite
â”‚   â”œâ”€â”€ page2.py                # Numerische Daten
â”‚   â”œâ”€â”€ page3.py                # Textuelle Daten
â”‚   â”œâ”€â”€ page4.py                # PlausibilitÃ¤tscheck
â”‚   â””â”€â”€ page5.py                # Data Drift
â”œâ”€â”€ assets/                     # Bilder (Logo, Favicon)
â”œâ”€â”€ resources/                  # Datenordner
â”‚   â”œâ”€â”€ Auftragsdaten           # Input Parquet
â”‚   â”œâ”€â”€ Positionsdaten          # Input Parquet
â”‚   â”œâ”€â”€ dashboard_data.duckdb   # Generierte Datenbank (durch build_db.py)
â”‚   â””â”€â”€ reports/                # HTML-Reports von Evidently
â”œâ”€â”€ build_db.py                 # ETL-Skript: Liest Parquet, berechnet Metriken, erstellt DB
â”œâ”€â”€ data_drift_metrics.py       # Wrapper fÃ¼r Evidently-Reports
â”œâ”€â”€ db_dashboard.py             # Hauptanwendung (Entry Point)
â”œâ”€â”€ metrics.py                  # Bibliothek fÃ¼r Berechnungslogik & ML-Modelle
â””â”€â”€ requirements.txt            # Python AbhÃ¤ngigkeiten
```

## ðŸš€ Installation & Setup

### 1. Repository klonen und Umgebung einrichten
Es wird empfohlen, eine virtuelle Umgebung (venv oder conda) zu nutzen.

```bash
git clone <repository-url>
cd <projekt-ordner>
python -m venv venv
source venv/bin/activate  # Auf Windows: venv\Scripts\activate
```

### 2. AbhÃ¤ngigkeiten installieren
```bash
pip install -r requirements.txt
```
*Hinweis: Da `torch` und `sentence-transformers` genutzt werden, kann die Installation je nach System einige Minuten dauern.*

### 3. Daten bereitstellen
Stelle sicher, dass die Quell-Dateien (Parquet-Format) im Ordner `resources/` liegen:
*   `resources/Auftragsdaten`
*   `resources/Positionsdaten`
*   `resources/Auftragsdaten_Zeit`

### 4. Datenbank aufbauen (ETL)
Bevor das Dashboard gestartet werden kann, mÃ¼ssen die Daten verarbeitet und die Metriken berechnet werden. Dies geschieht einmalig (oder bei Datenupdates) Ã¼ber das Build-Skript.

```bash
python build_db.py
```
*Das Skript fÃ¼hrt Data Cleaning durch, berechnet Embeddings auf der GPU (falls verfÃ¼gbar) und speichert alles in `resources/dashboard_data.duckdb`.*

### 5. Dashboard starten
```bash
streamlit run db_dashboard.py
```

## ðŸ§  Besonderheiten der Logik

### NLP & Vektorisierung (`metrics.py`)
Das Projekt nutzt das Modell `paraphrase-multilingual-MiniLM-L12-v2`, um zu prÃ¼fen, ob der Name eines Handwerkers semantisch zum angegebenen Gewerk passt.
*   **Performance:** Das Skript prÃ¼ft auf CUDA-VerfÃ¼gbarkeit. Auf einer CPU kann dieser Schritt bei groÃŸen DatensÃ¤tzen Zeit in Anspruch nehmen.
*   **Outlier-Detection:** EintrÃ¤ge mit einem Similarity-Score < 0.2 werden als potenzielle Mismatches markiert.

### Datenbank-Rotation
Das `build_db.py` Skript implementiert eine einfache Rotation. Die vorherige Datenbank wird als `dashboard_data_old.duckdb` gespeichert, um Delta-Vergleiche (VerÃ¤nderung der KPIs zum vorherigen Lauf) im Dashboard zu ermÃ¶glichen.

## ðŸ“Š Verwendung der Data Drift Reports
Auf Seite 5 ("Data Drift") kÃ¶nnen ZeitrÃ¤ume fÃ¼r Referenz- und Vergleichsdaten ausgewÃ¤hlt werden.
*   Wird ein Report angefordert, der noch nicht existiert, wird dieser *on-the-fly* berechnet und im Ordner `resources/reports/` als HTML gespeichert.
*   Bereits erstellte Reports werden gecached und direkt geladen.